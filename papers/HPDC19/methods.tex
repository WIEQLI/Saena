\section{Methods}
\label{sec:methods}

In this section, we present our matrix-matrix multiplication. We then explain further modifications to the triple matrix multiplication (\ref{eq:rap}) that are part of the AMG setup process.

\subsection{Matrix-Matrix Multiplication}
\label{sec:matmult}

%\subsubsection{Computation}
%\label{sec:comp}
We design a divide and conquer approach to performing the sparse \mm\ in a node-local fashion. The key idea is to perform simple tasks while recursing, having efficient memory access, and to perform the multiplication for small chunks where the resulting matrix can fit into an appropriate cache. For clarity of presentation, we assume that the data is available locally and discuss it as a serial implementation. Shared memory parallelism is added in a straightforward manner. We have implemented \mm~ in a recursive fashion. We split the matrices recursively in two ways: split by half based on the matrix size, split by half based on number of nonzeros. First we explain the algorithms performing splitting based on the matrix sizes.

The recursive function, \recmm, includes three cases:
\begin{enumerate}
 \item Case 1: Stop the recursion: perform the multiplication.
 \item Case 2: A is horizontal.
 \item Case 3: A is vertical.
\end{enumerate}

\subsubsection{Case 1}
\label{sec:case1}
At the start of the recursive function, the number of nonzero rows of A ($A\_nnz\_row$) and nonzero columns of B ($B\_nnz\_col$) are being computed. A threshold for $\nnzsz = A\_nnz\_row \times B\_nnz\_col$ is set. Our algorithm has a profiling step where it empirically determines the appropriate threshold by running several test cases. On the machines we used,  $20M$ was chosen as the threshold. We continue splitting the matrices until the threshold is reached. Then, we preform the multiplication. We have implemented two methods for this case: dense data structure and hashmap.

%First method uses a dense matrix.
%The matrices are ordered as column-major.
% In the first method, a dense matrix of size $\nnzsz$ is initialized to $0$. \mr{explain better:}Each nonzero of $B$ is multiplied by its corresponding nonzero of $A$ and the result will be added to the corresponding index in the dense matrix. At the end, we go through the dense matrix and add the nonzeros to the final multiplication matrix.
When performing the multiplication, at least one of the matrices, typically the output, needs random access as it is accumulating the results. Given that the divide and conquer approach has reduced the size of the output matrix, the first approach is to keep a temporary buffer for dense matrix storage. Each nonzero of $B$ is multiplied by its corresponding nonzero of $A$ and the result will be added to the corresponding index in the dense matrix. As long as the dense matrix is small enough to fit within the L2 cache, we should get good performance. At the end of the multiplication, we traverse the dense matrix and extract the non-zeros as a sparse matrix. This approach works well as long as the resulting matrix is dense. 

When $\nnzsz$ gets larger, it becomes inefficient to traverse the whole dense matrix and check for nonzeros in the final stage. To solve this issue, we use an efficient hashmap to achieve similar results without the $\mathcal{O}(n^2)$ overhead of extracting the non-zeros from the dense matrix. The entry's index is the key and its value is the hashmap's value. When we want to add the multiplication of nonzeros of $A$ and $B$ to the hashmap, we check if the index exists in the map. If it exists the value is being added to the existing one's. Otherwise a new entry will be added to the hashmap. Clearly, there is an overhead to this approach that needs to be balanced against the overheads associated with the dense representation. 

In Figure~\ref{fig:lap60}, we compare the two methods for a 3D Poisson problem of size $216k$. For $0 \leq \nnzsz \leq 10M$, in $1M$ steps, we compare the two methods in order to develop an efficient hybrid algorithm. For the lower range the dense representation is better and for the higher range the hashmap is significantly faster. Figure~\ref{fig:eco} shows the same experiment for matrix ID $1882$ from SuiteSparse (Florida) Matrix Collection. \mr{what is special about this matrix? At least give a description, so people know what it is. Better than giving the number.}

\begin{figure}[tbh]
 \centering
 \Description{Description}
 \includegraphics[width=8.5cm,height=4cm]{./figures/lap60_range.pdf}
 \caption{Case 1: comparison between dense structure method with hashmap for a 3D Poisson problem of size $216k$. The plot shows the number of times each method was better than the other one in intervals of $1M$ for $\nnzsz$.}
 \label{fig:lap60}
\end{figure}

\begin{figure}[tbh]
 \centering
 \Description{Description}
 \includegraphics[width=8.5cm,height=4cm]{./figures/eco_range.pdf}
 \caption{Case 1: comparison between dense structure method with hashmap for matrix ID $1882$ from SuiteSparse (Florida) Matrix Collection. The plot shows the number of times each method was better than the other one in intervals of $1M$ for $\nnzsz$}
 \label{fig:eco}
\end{figure}

A combination of these two methods would give us the best performance across different matrix structures and densities. The dense method is being used for the lower range and the hashmap for the higher range. Figure ~\ref{fig:mix} compares the hybrid method with the basic two methods. \mr{How did you determine the hybrid algorithm. 1-2 lines on that.} \mr{Also, discuss the results. Change mix to hybrid.}

\begin{figure}[tbh]
 \centering
 \Description{Description}
 \includegraphics[width=8.5cm,height=5cm]{./figures/mix.pdf}
 \caption{Comparison between three ways to do Case 1: only using hashmap, only using the dense structure, and a mix of both of them. \mr{longer caption, more details. It should be clear what is being done here.}}
 \label{fig:mix}
\end{figure}



\subsubsection{Case 2}
\label{sec:case2}
When A is horizontal, i.e. its row size is less than or equal to its column size, we halve A by column based on its column size (Figure ~\ref{fig:case2}). Since row size of B equals column size of A, we halve B by row, so it will be a split similar to A, but horizontally.
Then, the \recmm~ will be called twice, once on $A1$ and $B1$, and again on $A2$ and $B2$ (Algorithm~\ref{alg:case2}). The results of the two multiplications will need to be added together in the end. \mr{elaborate more. e.g.} In the sparse representation, this is similar to iterating over both lists once to merge and accumulate the results and is very efficient. 

\begin{figure}[tbh]
 \centering
 \Description{Description}
 \includegraphics[width=6cm,height=2.7cm]{./figures/case2_001.pdf}
 \caption{Case 2: When A is horizontal, split A by column and B by row. Call the recursive function twice, and add the result together at the end.}
 \label{fig:case2}
\end{figure}

\begin{algorithm}[H] 
  %\footnotesize
  \caption{Case 2: $C = \recmm2(A, B)$} \label{alg:case2} 
  \begin{algorithmic}[1]
    \Require $A$, $B$
    \Ensure  $C$
    \State $(A1, A2) = \spc(A)$
    \State $(B1, B2) = \spr(B)$
    \State $C \leftarrow \recmm(A1,B1)$
    \State $C \leftarrow \recmm(A2,B2)$
    %\State $C \leftarrow \textsc{mergesort}(C1, C2)$
  \end{algorithmic}
\end{algorithm}

\subsubsection{Case 3}
\label{sec:case3}
When A is vertical, i.e. its row size is greater than its column size, we halve A by row based on its row size and halve B by column (Figure ~\ref{fig:case3}). In contrary to the previous case, the column size of B is not related to row size of A, so they are split independently. This time the \recmm~ will be called four times (Algorithm~\ref{alg:case2}). \mr{Again we are missing details. This should be described in more details. I am adding some text, but check for correctness.} Although we have 4 recursive calls in this case, combining the results together is much simpler, as no additions need to be done, and simply merging the 4 results is sufficient.

\begin{figure}[tbh]
 \centering
 \Description{Description}
 \includegraphics[width=6cm,height=2.5cm]{./figures/case3_001.pdf}
 \caption{Case 3: When A is vertical, split A by row and B by column. Call the recursive function four times.}
 \label{fig:case3}
\end{figure}

\begin{algorithm}[H] 
  %\footnotesize
  \caption{Case 3: $C = \recmm3(A, B)$} \label{alg:case3} 
  \begin{algorithmic}[1]
    \Require $A$, $B$
    \Ensure  $C$
    \State $(A1, A2) = \spr(A)$
    \State $(B1, B2) = \spc(B)$
    \State $C \leftarrow \recmm(A1,B1)$
    \State $C \leftarrow \recmm(A2,B1)$
    \State $C \leftarrow \recmm(A1,B2)$
    \State $C \leftarrow \recmm(A2,B2)$
    %\State $\textsc{sort}(C)$
  \end{algorithmic}
\end{algorithm}

We have also implemented splitting based on the number of nonzeros. In \textit{Case 2}, we split $A$ in a way to have half of nonzeros in $A1$, and the other half in $A2$. The same split is used for $B$. In \textit{Case 3}, we do the same, but separately for both $A$ and $B$. \mr{This is fine, but I think you can expand this and add why this works. i.e., the zero rows will not be there in the multiplication, so we can skip them and make it more efficient. Also note the recursive splitting increases the probability of getting zero rols and columns}.

\subsubsection{All together}

When all three cases work together, we have Case 2 and Case 3, that aim to divide the matrices into skinny matrices such that the resulting matrix is small. Then by using a hybrid multiplication algorithm, we get these results. These results are then accumulated and merged together. From a memory access perspective, the accumulation and merging required for Case 2 and 3 is structured access to the matrix, with the only random access happening during Case 1. This makes the overall algorithm very efficient. 

\subsection{AMG Matrix-Multiplication: Communication}
\label{sec:amg}

% To solve a large linear system 
% \begin{equation}
%  Ax = b
% \end{equation}
% using an Algebraic Multigrid approach, we scale down the system, solve it directly, then scale back the solution. To scale down the system, three different categories of matrices are being created: coarse matrices ($As$), restriction matrices ($Rs$) and prolongation matrices ($Ps$). To study how $Ps$ and $Rs$ are computed you can refer to \cite{bell2012exposing, treister2015non}. Here we focus how to compute $As$, assuming $Ps$ and $Rs$ are available. We explain how to compute the first coarse matrix, the next ones can be computed similarly.

% original text starts here 
As noted earlier, to compute the coarse matrix $Ac$, a triple matrix multiplication is performed:
\begin{equation}
 Ac = R \times A \times P
\end{equation}
with $R = P^T$ in the Galerkin approach, which we use in our implementation.
%
In this section, we explain how the communication is setup to compute the coarse matrix $Ac$, exploiting properties of the matrix structure specific to AMG. 
%
Matrices are partitioned across multiple processors by row blocks (Figure~\ref{fig:partition}). Matrices $A$ and $P$ have the same number of rows and consequently are partitioned the same way. $R$ has fewer number of rows and has a different partition. This is because coarsening need not be uniform across processes. Consequently the partitioning of the rows of $R$ could be different from that of $A$ and $P$. The triple matrix product is performed in two parts: first $A \times P$ is computed, followed by $R \times B$, where $B = A \times P$ is the result of the first multiplication. In other words, this is equivalent to performing matrix-matrix multiplications (\mm) twice.

\begin{figure}[tbh]
 \centering
 \Description{Description}
 \includegraphics[width=8cm,height=3cm]{./figures/partition.pdf}
 \caption{Partitioning of the matrices across the processors in row blocks. $A$ and $P$ have the same partition but $R$'s is different.}
 \label{fig:partition}
\end{figure}

\subsubsection{Part 1}

In this part, we explain how to compute $B := A \times P$. We assume the same partition of rows of $A$ on also its columns (red lines) since $A$ is symmetric. For columns of $P$ we use the partition of rows of $R$ (blue lines in Figure~\ref{fig:part1b}).
Without loss of generality, let us focus on how to perform \mm ~on processor $P1$. To compute entry $B(i, j)$, we need to multiply row $i$ of $A$ with column $j$ of $P$ and add them together (since we are working with sparse matrices, we only consider the nonzeros).

\begin{figure}[tbh]
 \centering
 \Description{Description}
 \includegraphics[width=5.5cm,height=3cm]{./figures/part1b.pdf}
 \caption{This figure shows how the matrices are split into sub-blocks in Part 1. Column $j$ of $P$ is stored on different processors.}
 \label{fig:part1b}
\end{figure}

Column $j$ of $P$ is distributed between all the processors. Therefore we need to communicate all nonzeros of that column and then perform $B_{ij} = \sum_{k} A_{ik} P_{kj}$. Since that can lead to significant communication, we make use of the fact that $R$ is the transpose of $P$ and is already available locally because of the multigrid hierarchy. We note that column blocks of $P$ (e.g. $r0$ in Figure~\ref{fig:part1c}) are actually row blocks of $R$ transposed ($rt0$, which is transpose of $r0$). Algorithm \ref{alg:part1} shows how we do it in an overlapped fashion. $B_{i}$ is the row block of matrix $B$ on processor $i$ and $B_{ik}$ is the sub-block result of multiplying $A_i$ with $rt_i$. \mr{this is good, but describe overlapping in the text too ... not just the alg. }

\begin{figure}[tbh]
 \centering
 \Description{Description}
 \includegraphics[width=5.5cm,height=3cm]{./figures/part1c.pdf}
 \caption{This figure shows how row block of $R$ are transpose of column blocks of $P$.}
 \label{fig:part1c}
\end{figure}

\begin{algorithm}[H] 
  %\footnotesize
  \caption{Part 1: $B_i = A_i \times P$} \label{alg:part1} 
  \begin{algorithmic}[1]
    \Require $A_i$, $R$
    \Ensure  $B_i$ (result of $A_i \times P$)
    \State $R1 \leftarrow$ transpose of $R_i$ (locally)
    \For{$k=myrank:myrank+nprocs$}
      \State $R2 \leftarrow\ Irecv(transpose\ of\ R block)\ from\ right\ neighbor$
      \State $Isend(R1)\ to\ left\ neighbor$
      \State $B_{ik} \leftarrow \recmm(A_i, R1)$ 
      \State $wait\ for\ Isend\ and\ Irecv\ to\ finish$
      \State $swap(R1,R2)$
    \EndFor
    \State locally sort $B_i$ and add duplicates
  \end{algorithmic}
\end{algorithm}


\subsubsection{Part 2}

Now we explain how to do the second \mm: $R \times B$. The blocks of $R$ on processor $P1$ in, Figure~\ref{fig:part2d}, should be multiplied with the corresponding blocks of $B$ with the same color. In contrary to the previous part, we already don't have the transpose of the right-hand side matrix and performing the transpose or communicating whole matrix $B$ between processors is expensive. Instead, we change the way the multiplication is being done and instead perform a cheaper communication round at the end.

\begin{figure}[tbh]
 \centering
 \Description{Description}
 \includegraphics[width=5.5cm,height=3cm]{./figures/part2d.pdf}
 \caption{Part 2: $R \times B$. This figure shows which sub-blocks of R should be multiplied by which sub-blocks of $B$.}
 \label{fig:part2d}
\end{figure}

In this case we have the transpose of the left-hand side matrix, so we use $P$ instead of $R$ to do this multiplication.
We only perform the multiplication of the green blocks on processor $P1$ in Figure~\ref{fig:part2e}, which can be done locally.
%
In the previous case each sub-block of the local left-hand side is multiplied by only one sub-block of the local right-hand side.
But in this method, each sub-block of local $P$ is being multiplied by the entire row block of $B$, i.e. $PT10$ is multiplied by all $B10$, $B11$ and $B12$, and so on.

\begin{figure}[tbh]
 \centering
 \Description{Description}
 \includegraphics[width=5.5cm,height=3cm]{./figures/part2e.pdf}
 \caption{1}
 \label{fig:part2e}
\end{figure}

The difference for final result between this case and the na\"{i}ve Case 2 is that, the final entries are not on the correct processors, so an additional data exchange needs to be performed at the end to restore the entries on the correct processes. We sort the entries locally at the end and add the duplicates together. Finally, we sort them globally (using HykSort \cite{Sundar:2013}) and again add the duplicates together (Algorithm~\ref{alg:part2}).

\begin{algorithm}[H] 
  %\footnotesize
  \caption{Part 2: $Ac = R \times B$} \label{alg:part2} 
  \begin{algorithmic}[1]
    \Require $P_i$, $B_i$
    \Ensure  $Ac_i$
    \State $PT_i \leftarrow$ transpose of $P_i$ (locally)
    \For{$k=0:nprocs$}
      \State $Ac_i \leftarrow \recmm(PT_{ik}, B_i)$
    \EndFor
    \State locally sort $Ac_i$ and add duplicates
    \State globally sort $Ac_i$ and add duplicates
  \end{algorithmic}
\end{algorithm}
